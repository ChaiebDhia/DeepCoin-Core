# ğŸª™ DeepCoin-Core

> **An Agentic Multi-Modal System for Archaeological Numismatics & Historical Synthesis**

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB.svg?logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.6+-EE4C2C.svg?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-009688.svg?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-15+-000000.svg?logo=nextdotjs&logoColor=white)](https://nextjs.org/)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.3+-1C3C3C.svg)](https://langchain-ai.github.io/langgraph/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg?logo=docker&logoColor=white)](https://docs.docker.com/compose/)
[![License](https://img.shields.io/badge/License-MIT-F7DF1E.svg)](LICENSE)
[![GitHub Actions](https://img.shields.io/badge/CI%2FCD-GitHub_Actions-2088FF.svg?logo=githubactions&logoColor=white)](https://github.com/features/actions)

---

## Overview

**DeepCoin-Core** is an end-to-end industrial AI system that classifies degraded archaeological coins and synthesizes verified historical reports. It combines a fine-tuned **EfficientNet-B3 CNN** for visual classification with a **5-agent LangGraph state machine** for historical reasoning, delivering sub-second inference and professional PDF reports.

**Context**: PFE Final Year Engineering Internship â€” ESPRIT School of Engineering Ã— YEBNI, Tunisia (Feb â€“ Jul 2026)

---

## The Problem

Archaeological coins present a unique classification challenge:

- **Physical degradation** â€” worn by centuries of circulation and corrosion
- **Fragmentation** â€” broken or incomplete specimens
- **Fine-grained similarity** â€” subtle visual differences between hundreds of types
- **Data scarcity** â€” severe long-tail distribution (many types have <10 images)
- **Domain gap** â€” standard ImageNet pre-trained models fail on ancient coinage

A numismatic expert would spend 1â€“2 hours identifying a single corroded specimen. A museum with 500 unidentified coins faces weeks of manual work.

**DeepCoin reduces this to under 2 seconds per coin, always returning a useful output.**

---

## Solution: Two-Stage Hybrid AI Pipeline

### Stage 1 â€” Deep Learning (Physical Analysis)

```
Raw coin photo
    â†“
CLAHE Enhancement (LAB color space, L-channel only)
    â†’ Reveals worn surface details without color distortion
    â†“
Aspect-preserving resize â†’ 299Ã—299 with zero-padding
    â†’ Preserves coin geometry (no distortion)
    â†“
EfficientNet-B3 (12M params, ImageNet pretrained, fine-tuned)
    â†’ 1536-dimensional feature extraction
    â†’ Softmax probabilities across 438 coin classes
    â†’ Output: top-1 class + confidence score + top-5 predictions
```

### Stage 2 â€” Agentic AI (Historical Reasoning)

The CNN confidence score routes the analysis to the appropriate specialist agent:

```
confidence > 0.85  â†’  Historian Agent
                      ChromaDB semantic search â†’ Nomisma SPARQL â†’ LLM synthesis
                      Returns: emperor, period, mint, significance, sources

0.40 â‰¤ conf â‰¤ 0.85 â†’  Forensic Validator Agent
                      OpenCV color histogram analysis (metal type detection)
                      Historical consistency checks
                      â†’ If anomaly: Human Review Queue
                      â†’ If clean: synthesis

confidence < 0.40  â†’  Visual Investigator Agent
                      Vision-Language Model (Gemini 2.5 Flash via GitHub Models)
                      Zero-shot attribute extraction: metal, portrait, inscription, symbols
                      Ensures no empty response for unknown coin types

All paths â†’ Editor-in-Chief (Synthesis Agent)
          â†’ Structured Markdown report â†’ PDF
          â†’ FastAPI response â†’ Next.js renders report
```

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER (Browser)                                 â”‚
â”‚         Next.js 15 + TypeScript + Tailwind CSS + shadcn/ui          â”‚
â”‚    Upload â†’ Live Agent Progress (WebSocket) â†’ PDF Report Viewer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP / WebSocket
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Nginx (Port 80) â€” Reverse Proxy                  â”‚
â”‚          /api/* â†’ FastAPI (port 8000)  |  /* â†’ Next.js (port 3000) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI + Uvicorn (Port 8000)                      â”‚
â”‚  POST /api/classify  |  GET /api/health  |  GET /api/history        â”‚
â”‚  GET  /api/history/{id}  |  WS /ws/classify/{session_id}           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             LangGraph State Machine â€” Gatekeeper Orchestrator       â”‚
â”‚                                                                     â”‚
â”‚  [preprocess] â†’ [vision_cnn] â†’ route_by_confidence()               â”‚
â”‚                                                                     â”‚
â”‚  conf < 0.40  â†’ [investigator] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  0.40â€“0.85   â†’ [validator] â†’ human_review? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚  conf > 0.85  â†’ [historian] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚                                                       â–¼             â”‚
â”‚                                               [synthesis]           â”‚
â”‚                                         Markdown â†’ PDF report       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChromaDB           â”‚              â”‚  LLM Fallback Chain            â”‚
â”‚  CN metadata        â”‚              â”‚  1. GitHub Models (Gemini 2.5) â”‚
â”‚  indexed vectors    â”‚              â”‚     â†’ free, Copilot Pro        â”‚
â”‚  semantic search    â”‚              â”‚  2. Google AI Studio (Gemini)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚     â†’ free tier, 1,500 req/day â”‚
                                     â”‚  3. Nomisma.org SPARQL         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â†’ academic linked open dataâ”‚
â”‚  Data Persistence Layer          â”‚ â”‚  4. Wikipedia API (last resort)â”‚
â”‚  PostgreSQL â€” history, audit log â”‚ â”‚     â†’ prose only, flagged      â”‚
â”‚  Redis       â€” result cache      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  LocalStack S3 â€” image storage   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The 5-Agent Sovereign Squad

### 1. Gatekeeper (Orchestrator)
The LangGraph state machine brain. Routes every analysis based on CNN confidence to the appropriate specialist. Manages the `CoinState` shared by all agents. Features: structured `logging` with per-node timing (cnn / historian / validator / investigator / synthesis), retry with exponential backoff (2Ã—, 1.5sâ†’3.0s) on LLM 429/503 errors, and graceful per-node degradation â€” one failing agent stores `{"_error": ...}` in its result and lets the pipeline reach synthesis instead of crashing.

**Routing thresholds**: `< 0.40` â†’ Investigator | `0.40â€“0.85` â†’ Validator + Historian | `> 0.85` â†’ Historian

### 2. Visual Investigator (Attribute Expert)
Handles low-confidence and out-of-distribution coins. Sends the coin image to a Vision-Language Model (`qwen3-vl:4b` via Ollama) and extracts structured visual attributes â€” metal color, portrait direction, visible inscription characters, iconographic symbols. When no vision model is available, falls back to a local OpenCV analysis: HSV histogram across 3 crop sizes for metal detection, Sobel edge density for condition estimate. Cross-references the full 9,541-type KB â€” not just the 438 CNN training types. Always returns a useful analytical output, even if the CNN cannot classify.

### 3. Forensic Validator (Truth Seeker)
Applies multi-scale OpenCV HSV forensic analysis to mid-confidence predictions. Runs independently on three center-crop sizes (40% / 60% / 80%) and takes a majority vote on the detected metal (gold / bronze / silver). Returns `detection_confidence` (float 0â€“1, mean pixel coverage) and `uncertainty` (low/medium/high based on scale agreement). Compares detected metal against the KB-stored expected material for the predicted type. Flags material mismatches in the report.

### 4. Historian (RAG Specialist)
Retrieves verified historical context for high-confidence predictions. Queries the hybrid RAG engine (BM25 + ChromaDB vector + RRF merge over 47,705 chunks). Injects retrieved chunks as labeled `[CONTEXT 1â€“5]` blocks into the LLM prompt with a strict instruction: *"Using ONLY the contexts above (cite [CONTEXT N]), write a 3-paragraph professional analysis. Do not add any fact not present in the context."* Supports 4 LLM providers: GitHub Models â†’ Google AI Studio â†’ Ollama (gemma3:4b) â†’ fallback (KB field concatenation, no hallucination).

### 5. Editor-in-Chief (Synthesis Agent)
Compiles all agent outputs into a single structured plain-text report and converts it to a professional PDF. PDF is rendered entirely with direct fpdf2 draw primitives â€” no Markdown parsing, no external font loading. Features: navy header band, bordered tables with alternating row shading, blue section rule lines, Greek-to-Latin transliteration (`_GREEK_MAP`, 48 chars) so ancient legends render correctly in Latin-1 encoded fonts.

---

## LangGraph State Contract

All agents communicate exclusively through this shared state:

```python
class CoinState(TypedDict, total=False):
    # inputs
    image_path          : str
    use_tta             : bool
    # after cnn_node
    cnn_prediction      : dict    # {"class_id": int, "label": str, "confidence": float, "top5": list, "tta_used": bool}
    route_taken         : Literal["historian", "validator", "investigator"]
    # agent outputs
    historian_result    : dict    # narrative, mint, date, material, llm_used, _error (if any)
    validator_result    : dict    # status, detection_confidence, uncertainty, warning, _error (if any)
    investigator_result : dict    # visual_description, detected_features, kb_matches, llm_used, _error (if any)
    # per-node timing (seconds, set progressively by each node)
    node_timings        : dict    # {"cnn": 0.54, "historian": 14.37, "synthesis": 0.47}
    # final outputs
    report              : str     # plain-text summary
    pdf_path            : Optional[str]
```

**Key design rule**: the `label` field (folder name = CN type ID, e.g. `"1015"`) must be used for all KB lookups, NOT `class_id` (which is the 0â€“437 softmax tensor index).

---

## Technology Stack

### Deep Learning

| Technology | Version | Purpose |
|---|---|---|
| PyTorch | 2.6.0+cu124 | Neural network training and inference |
| torchvision | 0.21+ | EfficientNet-B3 pretrained weights |
| EfficientNet-B3 | ImageNet pretrained | 12M param CNN, 1536-dim features, 438-class head |
| OpenCV | 4.10+ | CLAHE preprocessing, HSV histogram forensics |
| Albumentations | 1.4+ | Training augmentation pipeline |
| NumPy | 2.x | Numerical operations |

### Agentic AI

| Technology | Version | Purpose |
|---|---|---|
| LangGraph | 0.3+ | State machine orchestration with cycles and conditional routing |
| LangChain | 0.3+ | Agent tooling and prompt management |
| Gemini 2.5 Flash | via GitHub Models | VLM for visual description (free, Copilot Pro) |
| Gemini 2.5 Flash | via Google AI Studio | LLM fallback (free tier, 1,500 req/day) |
| ChromaDB | 0.6+ | Local vector database for RAG |
| sentence-transformers | 3.3+ | Text embeddings for semantic search |

### Backend

| Technology | Version | Purpose |
|---|---|---|
| FastAPI | 0.115+ | Async Python web framework with auto-docs |
| Uvicorn | 0.40+ | ASGI server |
| Pydantic | 2.x | Request/response validation schemas |
| SQLAlchemy | 2.x | PostgreSQL ORM (async) |
| Alembic | Latest | Database migration versioning |

### Frontend

| Technology | Version | Purpose |
|---|---|---|
| Next.js | 15 | React framework with Server Components |
| TypeScript | 5 | Type-safe JavaScript |
| Tailwind CSS | 4 | Utility-first styling |
| shadcn/ui | Latest | Accessible component library (Radix UI) |
| TanStack Query | 5 | Server state management and caching |
| Zustand | 4 | Lightweight client state |

### Infrastructure

| Technology | Version | Purpose |
|---|---|---|
| Docker Compose | 2.x | Multi-container local orchestration |
| PostgreSQL | 17 | Relational database (ACID, JSONB) |
| Redis | 7 | Result caching and session management |
| Nginx | 1.27 | Reverse proxy and load balancing |
| LocalStack | 3.x | AWS S3 + Lambda local simulation |
| GitHub Actions | â€” | CI/CD: test, lint, format on every push |
| pytest | 8.x | Python unit and integration testing |
| Jest + Playwright | 30 / 1.50+ | Frontend unit and end-to-end testing |

---

## Performance

| Metric | Value | Notes |
|---|---|---|
| CNN Test Accuracy | 79.08% | Single-pass, 438 classes, 1,152 test images |
| CNN Accuracy (TTA) | **80.03%** | 8-pass Test-Time Augmentation (+0.78%) |
| Mean F1 Score | 0.7763 | Macro-averaged across 438 classes |
| Top Confusion Pair | 3314 â†’ 3987 | 10Ã— misclassification frequency |
| Target Accuracy | >85% | Gap: ~5pp |
| Training Duration | ~103 min | RTX 3050 Ti (4.3 GB VRAM), CUDA 12.4 |
| Best Epoch | 52 / 100 | Val accuracy 79.25%, early stopping patience=10 |
| Pipeline (Historian) | ~15 s | CNN + RAG lookup + Ollama gemma3:4b + PDF |
| Pipeline (Validator) | ~10 s | CNN + multi-scale HSV + Historian + PDF |
| Pipeline (Investigator) | ~3 s | CNN + OpenCV fallback + KB search + PDF |
| KB search latency | < 1 ms | ChromaDB + BM25, 47,705 vectors |
| PDF generation | ~0.4 s | Direct fpdf2 draw, Greek transliteration |

---

## Dataset

### Corpus Nummorum (CN) v1

| Property | Value |
|---|---|
| Source | [corpus-nummorum.eu](https://www.corpus-nummorum.eu/) |
| Total images | 115,160 ancient coin photographs |
| Original classes | 9,716 unique coin types |
| Distribution | Severe long-tail â€” majority of types have <10 images |

### Filtered Dataset (Training Ready)

| Property | Value |
|---|---|
| Classes | 438 (filtered: â‰¥10 images per class) |
| Total images | 7,677 preprocessed images |
| Average per class | 17.5 images |
| Image size | 299Ã—299 RGB JPEG |
| Preprocessing | CLAHE (LAB, clipLimit=2.0, tile=8Ã—8) + aspect-preserving resize |
| Split | 70% train / 15% validation / 15% test (stratified, seed=42) |

**Filtering rationale**: CNNs cannot reliably learn to classify from 1â€“3 examples. Applying a hard threshold of â‰¥10 images per class sacrifices breadth (438 vs 9,716 types) in exchange for classification reliability. Transfer learning from ImageNet reduces the minimum data requirement from thousands of examples to tens.

---

## Quick Start

### Prerequisites

- Python 3.11+
- Git
- NVIDIA GPU with CUDA 12.x (recommended for inference speed)

### Setup

```bash
# Clone
git clone https://github.com/ChaiebDhia/DeepCoin-Core.git
cd DeepCoin-Core

# Virtual environment
python -m venv venv
venv\Scripts\activate          # Windows
# source venv/bin/activate     # Linux/macOS

# Install dependencies
pip install -r requirements.txt
```

### Environment Variables

Create a `.env` file in the project root (never commit this file):

```env
# LLM providers (any one is enough â€” system tries in priority order)
GITHUB_TOKEN=ghp_your_token_here        # GitHub PAT with models:read scope (Priority 1)
GOOGLE_API_KEY=your_key_here            # Google AI Studio API key (Priority 2)

# Local Ollama (Priority 3 â€” runs fully offline)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gemma3:4b
OLLAMA_VISION_MODEL=qwen3-vl:4b        # For Investigator; fallback to OpenCV if not pulled

# Database (Layers 4-6)
POSTGRES_URL=postgresql://localhost:5432/deepcoin
REDIS_URL=redis://localhost:6379
LOCALSTACK_ENDPOINT=http://localhost:4566
```

### Data Preprocessing

```bash
# Place raw CN dataset in data/raw/CN_dataset_v1/
python src/data_pipeline/prep_engine.py
# Output: 7,677 processed images in data/processed/
```

### CNN Training (already completed â€” model in models/)

```bash
python scripts/train.py
# Trains EfficientNet-B3, saves best checkpoint to models/best_model.pth
# Best result: 79.08% test accuracy (80.03% with TTA)
```

### Model Evaluation

```bash
# Standard evaluation
python scripts/audit.py
# Output: confusion matrix, per-class F1, top-K accuracy

# Test-Time Augmentation evaluation
python scripts/evaluate_tta.py
# Result: +0.95% accuracy improvement
```

### Run the Full Pipeline (Layer 3 â€” Production Ready)

```bash
# Run all 3 routing paths (historian / validator / investigator)
# Logs: per-node timing, confidence, route, PDF path
python scripts/test_pipeline.py 2>$null

# Example single image prediction (CLI)
python scripts/predict.py data/processed/1015/CN_type_1015_cn_coin_5943_p.jpg --tta
# Output: type=1015  confidence=91.1%  label=1015  tta=True

# Rebuild ChromaDB (only needed if metadata changes)
python scripts/rebuild_chroma.py
# Duration: ~9 min  |  Output: 47,705 vectors in data/metadata/chroma_db_rag/
```

### Full Stack (Docker)

```bash
# Coming in Layer 6 â€” Docker Compose setup
docker compose up
# Services: FastAPI + Next.js + ChromaDB + PostgreSQL + Redis + Nginx + LocalStack
```

---

## Project Structure

```
DeepCoin-Core/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_pipeline/
â”‚   â”‚   â””â”€â”€ prep_engine.py          # CLAHE + aspect-preserving resize pipeline
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ model_factory.py        # EfficientNet-B3 definition (Dropout=0.4)
â”‚   â”‚   â”œâ”€â”€ dataset.py              # DeepCoinDataset + Albumentations transforms
â”‚   â”‚   â”œâ”€â”€ inference.py            # CoinInference class [Layer 1 â€” NEXT]
â”‚   â”‚   â””â”€â”€ knowledge_base.py       # ChromaDB client wrapper [Layer 2]
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ gatekeeper.py           # LangGraph orchestrator + routing logic
â”‚   â”‚   â”œâ”€â”€ historian.py            # RAG specialist (ChromaDB + Nomisma + LLM)
â”‚   â”‚   â”œâ”€â”€ investigator.py         # VLM agent (Gemini 2.5 Flash via GitHub Models)
â”‚   â”‚   â”œâ”€â”€ validator.py            # Forensic analysis (OpenCV histograms)
â”‚   â”‚   â””â”€â”€ synthesis.py            # Report generation (Markdown â†’ PDF)
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚       â”œâ”€â”€ routes/
â”‚       â”‚   â”œâ”€â”€ classify.py         # POST /api/classify [Layer 4]
â”‚       â”‚   â””â”€â”€ history.py          # GET /api/history [Layer 4]
â”‚       â””â”€â”€ schemas.py              # Pydantic request/response models [Layer 4]
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                    # CNN training loop (V3, 729 lines) âœ…
â”‚   â”œâ”€â”€ audit.py                    # Model audit â€” F1, confusion matrix âœ…
â”‚   â”œâ”€â”€ evaluate_tta.py             # TTA evaluation âœ…
â”‚   â”œâ”€â”€ predict.py                  # CLI inference tool [Layer 1 â€” NEXT]
â”‚   â””â”€â”€ build_knowledge_base.py     # CSV + Nomisma â†’ ChromaDB [Layer 2]
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pth              # V3 weights (epoch 52, val 79.25%, test 79.08%, TTA 80.03%) âœ…
â”‚   â”œâ”€â”€ best_model_v1_80pct.pth     # Early checkpoint (epoch 3, val 21.33%) â€” misleading name, NOT the 80% model
â”‚   â””â”€â”€ class_mapping.pth           # {class_to_idx, idx_to_class, n=438} âœ…
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/                  # 7,677 images Ã— 438 classes âœ…
â”‚   â”œâ”€â”€ metadata/                   # CN dataset CSVs â†’ Layer 2
â”‚   â””â”€â”€ raw/                        # Original dataset (gitignored)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                       # Per-module unit tests â†’ Layer 7
â”‚   â””â”€â”€ integration/                # End-to-end pipeline tests â†’ Layer 7
â”‚
â”œâ”€â”€ frontend/                       # Next.js 15 app â†’ Layer 5
â”œâ”€â”€ notebooks/                      # Exploration and analysis
â”‚
â”œâ”€â”€ docker-compose.yml              # 7-service orchestration â†’ Layer 6
â”œâ”€â”€ .github/workflows/ci.yml        # pytest + flake8 + black â†’ Layer 7
â”œâ”€â”€ requirements.txt                # All Python dependencies âœ…
â”œâ”€â”€ .env                            # Secrets (gitignored â€” NEVER COMMIT)
â””â”€â”€ .gitignore
```

---

## Build Layers â€” Current Progress

The system is built in strict dependency order. Each layer is completed and tested before the next begins.

| Layer | Name | Status | Description |
|---|---|---|---|
| 0 | CNN Training | âœ… Complete | EfficientNet-B3 trained at 80.03% TTA accuracy (438 classes, 7,677 images) |
| 1 | Inference Engine | âœ… Complete | `inference.py` + `predict.py` â€” TTA, device auto-resolve, structured prediction dict |
| 2 | Knowledge Base | âœ… Complete | 9,541 types scraped Ã— 5 semantic chunks = 47,705 ChromaDB vectors + BM25 index |
| 3 | Agent System | âœ… Complete | All 5 agents enterprise-grade; logging, retry, graceful degradation; 3/3 routes tested |
| 4 | FastAPI Routes | ğŸ”² Next | `POST /api/classify`, `GET /api/history`, WebSocket live progress |
| 5 | Next.js Frontend | ğŸ”² Pending | Upload UI, real-time agent progress, PDF inline viewer |
| 6 | Docker + Infra | ğŸ”² Pending | Full Docker Compose stack (7 services), Redis cache, LocalStack S3 |
| 7 | Tests + CI/CD | ğŸ”² Pending | pytest, Jest, Playwright, GitHub Actions |

**Layer 3 end-to-end results (February 27, 2026):**
```
Route 1 â€” HISTORIAN    : type=1015   conf=91.1%   time=15.4s   PDF âœ“   [PASS]
Route 2 â€” VALIDATOR    : type=21027  conf=42.9%   material=consistent  det_conf=0.73  time=9.8s    PDF âœ“   [PASS]
Route 3 â€” INVESTIGATOR : type=544    conf=21.3%   KB_matches=3  llm=False (OpenCV fallback)  time=3.1s  PDF âœ“   [PASS]
```

---

## CNN Training Configuration (V3)

```python
model         = EfficientNet-B3 (ImageNet pretrained, Dropout=0.4)
optimizer     = AdamW(lr=1e-4, weight_decay=0.01)
scheduler     = CosineAnnealingLR(T_max=100, eta_min=1e-6)
loss          = CrossEntropyLoss(label_smoothing=0.1)
augmentation  = Albumentations pipeline (rotation, brightness, elastic)
mixup         = alpha=0.2 (Beta distribution blending)
amp           = torch.amp.GradScaler('cuda') + autocast
gradient_clip = max_norm=1.0
batch_size    = 16  (GPU memory constraint: RTX 3050 Ti, 4.3GB VRAM)
early_stop    = patience=10 epochs on validation accuracy
pin_memory    = True
non_blocking  = True (async GPU transfer)
seed          = 42
```

---

## Key Engineering Decisions

| Decision | Choice | Rationale |
|---|---|---|
| CNN architecture | EfficientNet-B3 | Optimal accuracy/parameter ratio; B7 exceeds VRAM budget |
| Preprocessing | CLAHE in LAB space | Enhances contrast without distorting metal color values |
| Resize strategy | Aspect-preserving + zero-padding | Preserves coin geometry for accurate feature extraction |
| Agent framework | LangGraph | Conditional routing, cycles, human-in-loop â€” impossible in CrewAI |
| LLM Provider Chain | Priority order | 1. GitHub Models (Gemini 2.5 Flash, free) â†’ 2. Google AI Studio (free tier) â†’ 3. Ollama gemma3:4b (local) â†’ 4. Structured fallback (no LLM, no crash) |
| Vision LLM | qwen3-vl:4b via Ollama | For Investigator; OpenCV fallback if not downloaded |
| Primary data source | CN dataset metadata CSVs | On-disk, validated by Berlin-Brandenburg Academy of Sciences |
| External data | Nomisma.org SPARQL | Academic numismatic linked open data â€” structured, authoritative |
| Wikipedia | Last resort only | Unverifiable for facts; prose only; always flagged in output |
| Vector DB | ChromaDB | Local, embeddable, zero-config for development |
| Backend | FastAPI (async) | Auto-docs, Pydantic validation, async request handling |
| Cloud simulation | LocalStack | Demonstrate S3/Lambda skills without AWS account costs |

---

## Data Sources for Historical Context

The system uses a verified fallback chain â€” always using the most authoritative available source:

1. **CN Dataset Metadata** (primary) â€” Structured CSV data from Corpus Nummorum, validated by the Berlin-Brandenburg Academy of Sciences and the German Research Foundation (DFG)
2. **Nomisma.org SPARQL** (secondary) â€” Academic linked open data for numismatics; emperor names, reign periods, mint locations as structured RDF
3. **LLM Synthesis** (tertiary) â€” Gemini 2.5 Flash generates narrative prose from the structured data retrieved in steps 1â€“2; the LLM writes, it does not invent
4. **Wikipedia API** (last resort) â€” Used only for emperor biography narrative when no structured source covers the subject; always marked `"Source: Wikipedia (unverified)"`

---

## API Reference (Planned)

```
POST   /api/classify
       Body: multipart/form-data { image: File }
       Returns: ClassificationResult (JSON)

GET    /api/health
       Returns: { api, ml_model, agents, database, chromadb }

GET    /api/history
       Returns: List[ClassificationSummary]

GET    /api/history/{id}
       Returns: ClassificationResult (full)

WS     /ws/classify/{session_id}
       Streams: AgentProgressEvent (live agent status)
```

---

## Contributing

Contributions are welcome. Please follow the workflow:

```bash
git checkout -b feature/your-feature-name
# make changes
git commit -m "feat: description of change"
git push origin feature/your-feature-name
# open Pull Request
```

All PRs must pass: `pytest` + `flake8` + `black --check` via GitHub Actions CI.

---

## License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## Acknowledgements

- **[Corpus Nummorum](https://www.corpus-nummorum.eu/)** â€” Dataset, funded by the German Research Foundation (DFG) and Berlin-Brandenburg Academy of Sciences
- **[Nomisma.org](https://nomisma.org/)** â€” Numismatic linked open data standards
- **[PyTorch](https://pytorch.org/)** â€” Deep learning framework
- **[LangChain / LangGraph](https://langchain-ai.github.io/langgraph/)** â€” Agent orchestration
- **[FastAPI](https://fastapi.tiangolo.com/)** â€” Backend framework

---

## Contact

**Dhia Chaieb** â€” ESPRIT School of Engineering, Tunisia  
dhia.chaieb@esprit.tn | [@ChaiebDhia](https://github.com/ChaiebDhia)  
Internship partner: [YEBNI â€” Information & Communication](https://yebni.com)
