# ğŸª™ DeepCoin-Core: Industrial AI for Archaeological Numismatics

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5+-red.svg)](https://pytorch.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green.svg)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-15+-black.svg)](https://nextjs.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **DeepCoin is an end-to-end industrial AI solution designed to identify, classify, and analyze degraded archaeological coins. By combining Deep Learning (CNNs) for physical feature extraction and Generative AI (LangGraph Agents) for historical reasoning, DeepCoin transforms raw, corroded numismatic data into verified historical reports. Built with a scalable microservices architecture using FastAPI, Next.js, and AWS (via LocalStack).**

![DeepCoin Architecture](docs/architecture_diagram.png)

---

## ğŸ¯ Project Overview

**DeepCoin-Core** is an end-to-end industrial AI solution that bridges the gap between **computer vision** and **historical intelligence** for archaeological numismatics. The system combines:

### **Core Innovation: Two-Stage AI Pipeline**

1. **Deep Learning Stage (Physical Analysis)**
   - **EfficientNet-B3 CNN** trained on 7,677+ ancient coin images
   - Handles severe degradation: corrosion, wear, fragmentation
   - CLAHE preprocessing reveals hidden surface details
   - Transfer learning from ImageNet for robust feature extraction

2. **Generative AI Stage (Historical Reasoning)**
   - **LangGraph multi-agent orchestration** for complex decision-making
   - **RAG (Retrieval-Augmented Generation)** with ChromaDB vector database
   - Synthesizes CNN predictions into verified historical narratives
   - Human-in-the-loop validation for quality assurance

### **Technology Stack Highlights**

- ğŸ§  **Deep Learning**: PyTorch 2.5, EfficientNet-B3, OpenCV preprocessing
- ğŸ¤– **Agentic AI**: LangGraph state machines, GPT-4o-mini synthesis
- ğŸ“š **RAG System**: ChromaDB vector database, semantic search
- â˜ï¸ **Cloud-Native**: LocalStack AWS simulation (S3, Lambda)
- ğŸŒ **Web Stack**: Next.js 15 (React) + FastAPI + PostgreSQL
- ğŸ³ **DevOps**: Docker Compose, GitHub Actions CI/CD

### The Challenge

Archaeological coins are exceptionally difficult to classify due to:
- **Physical degradation**: Worn by centuries of circulation
- **Corrosion and patina**: Obscured surface details
- **Fragmentation**: Broken or incomplete specimens
- **Data scarcity**: Long-tail distribution with many rare types

### The Solution: Hybrid Deep Learning + Generative AI

**DeepCoin-Core** employs a two-stage intelligent pipeline:

#### **Stage 1: Deep Learning Classification**
1. **Preprocessing Engine**: CLAHE enhancement + aspect-preserving resize
2. **CNN Training**: EfficientNet-B3 fine-tuned on 438 coin classes
3. **Feature Extraction**: 1536-dimensional visual embeddings
4. **Prediction**: Softmax probabilities across coin types

## âœ¨ Key Features

### ğŸ”¬ Deep Learning Computer Vision Pipeline
- **EfficientNet-B3** CNN (12M parameters) fine-tuned for numismatics
- **CLAHE enhancement** (LAB color space) reveals worn coin details
- **Aspect-preserving preprocessing** maintains coin geometry (299Ã—299)
- **Transfer learning** from ImageNet â†’ 10-100x less training data needed
- **Data augmentation** (rotation, brightness, elastic transforms)
### ğŸ¤– Generative AI Agent Orchestration (LangGraph)
- **Orchestrator**: State machine with conditional routing & cycles
- **Vision Agent**: Wraps CNN inference + Grad-CAM visualization
- **Research Agent**: RAG system (ChromaDB + Wikipedia API + GPT-4o)
- **Validator Agent**: Historical consistency checks (dates, emperors, mints)
- **Synthesis Agent**: Markdown â†’ PDF report generation with citations
### ğŸŒ Industrial Microservices Architecture
- **FastAPI** backend (async, type-safe, auto-documented API)
- **Next.js 15** frontend (React Server Components, TypeScript)
- **PostgreSQL** database (ACID compliance, JSONB support)
- **Redis** cache (session management, API rate limiting)
- **LocalStack** AWS emulation (S3 storage, Lambda inference)
- **Docker Compose** multi-container orchestration
- **Nginx** reverse proxy with load balancing
- **Vision Agent**: CNN-based classification pipeline
- **Research Agent**: RAG system with ChromaDB vector database
- **Validator Agent**: Historical consistency verification
- **Synthesis Agent**: Professional PDF report generation

### ğŸŒ Production-Ready Architecture
- **FastAPI** backend with async operations
- **Next.js 15** frontend with Server Components
- **PostgreSQL** for persistent storage
- **LocalStack** for AWS S3/Lambda simulation
- **Docker Compose** for orchestration

### ğŸ“Š Intelligent Decision Making
```
Confidence > 85%  â†’ Auto-approve & log
Confidence 60-85% â†’ Request human review
## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FRONTEND (Next.js 15 + TypeScript)                â”‚
â”‚  â€¢ Image Upload Component (drag & drop)                     â”‚
â”‚  â€¢ Real-time Classification Dashboard                       â”‚
â”‚  â€¢ Confidence Visualization (charts)                        â”‚
â”‚  â€¢ PDF Report Viewer & Download                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ REST API / WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND API (FastAPI + Python)                 â”‚
â”‚  â€¢ POST /api/classify - Upload & classify coin              â”‚
â”‚  â€¢ GET /api/history/{id} - Retrieve historical context      â”‚
â”‚  â€¢ GET /api/validate/{id} - Expert review queue             â”‚
â”‚  â€¢ WebSocket /ws - Real-time agent progress streaming       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DEEP LEARNING INFERENCE ENGINE                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  1. CLAHE Preprocessing (OpenCV)                  â”‚     â”‚
â”‚  â”‚  2. EfficientNet-B3 Forward Pass (PyTorch)        â”‚     â”‚
â”‚  â”‚  3. Softmax Probabilities (438 classes)           â”‚     â”‚
â”‚  â”‚  4. Grad-CAM Attention Maps                       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         Output: {"class": 3987, "prob": 0.87, ...}         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      AGENTIC ORCHESTRATOR (LangGraph State Machine)         â”‚
â”‚  â€¢ Conditional Routing (confidence-based)                   â”‚
â”‚  â€¢ State Persistence (checkpoints)                          â”‚
â”‚  â€¢ Human-in-the-Loop Breakpoints                            â”‚
â”‚  â€¢ Retry Logic & Error Handling                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VISION AGENT   â”‚ â”‚ RESEARCH AGENT  â”‚ â”‚ VALIDATOR AGENT â”‚
â”‚                 â”‚ â”‚                 â”‚ â”‚                 â”‚
â”‚ â€¢ Extract CNN   â”‚ â”‚ â€¢ Query ChromaDBâ”‚ â”‚ â€¢ Date checks   â”‚
â”‚   predictions   â”‚ â”‚   vector DB     â”‚ â”‚ â€¢ Emperor/mint  â”‚
â”‚ â€¢ Generate      â”‚ â”‚ â€¢ Wikipedia API â”‚ â”‚   consistency   â”‚
â”‚   attention     â”‚ â”‚ â€¢ GPT-4o-mini   â”‚ â”‚ â€¢ Anomaly       â”‚
â”‚   maps          â”‚ â”‚   synthesis     â”‚ â”‚   detection     â”‚
â”‚ â€¢ Confidence    â”‚ â”‚ â€¢ Source        â”‚ â”‚ â€¢ Confidence    â”‚
â”‚   scoring       â”‚ â”‚   attribution   â”‚ â”‚   adjustment    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                   â†“                   â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       SYNTHESIS AGENT                 â”‚
        â”‚  â€¢ Aggregate all agent outputs        â”‚
        â”‚  â€¢ Calculate final confidence score   â”‚
        â”‚  â€¢ Generate Markdown report           â”‚
        â”‚  â€¢ Convert to professional PDF        â”‚
        â”‚  â€¢ Include citations & sources        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        DECISION LAYER                 â”‚
        â”‚  Confidence > 85%: âœ… Auto-approve    â”‚
        â”‚  Confidence 60-85%: âš ï¸ Human review   â”‚
        â”‚  Confidence < 60%: ğŸš© Flag expert     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               DATA PERSISTENCE LAYER                        â”‚
â”‚  â€¢ PostgreSQL: Users, classifications, audit logs           â”‚
â”‚  â€¢ ChromaDB: Historical text embeddings (RAG)               â”‚
â”‚  â€¢ Redis: Session cache, API rate limiting                  â”‚
â”‚  â€¢ LocalStack S3: Image storage (simulated AWS)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Synthesis   â”‚
                   â”‚    Agent     â”‚
                   â”‚ PDF Reports  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Node.js 18+** (for frontend, coming soon)
- **Docker & Docker Compose**
- **Git**

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/ChaiebDhia/DeepCoin-Core.git
cd DeepCoin-Core

# 2. Create virtual environment
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Download dataset (CN Dataset v1)
# Place in: data/raw/CN_dataset_v1/

# 5. Run data preprocessing
python src/data_pipeline/prep_engine.py
```

### Project Structure

```
DeepCoin-Core/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_pipeline/      # Deep Learning data preprocessing
â”‚   â”‚   â”œâ”€â”€ auditor.py      # Dataset analysis & long-tail filtering
â”‚   â”‚   â””â”€â”€ prep_engine.py  # CLAHE enhancement + resize pipeline
â”‚   â”œâ”€â”€ core/               # CNN architecture & training
â”‚   â”‚   â””â”€â”€ model_factory.py # EfficientNet-B3 model definition
â”‚   â”œâ”€â”€ agents/             # Generative AI agents (LangGraph)
â”‚   â”œâ”€â”€ api/                # FastAPI microservices backend
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original CN dataset (gitignored)
â”‚   â”œâ”€â”€ processed/          # Preprocessed 299x299 images
â”‚   â””â”€â”€ metadata/           # Dataset statistics
â”œâ”€â”€ models/                 # Trained model checkpoints
â”œâ”€â”€ tests/                  # Unit & integration tests
â”œâ”€â”€ notebooks/              # Jupyter notebooks for experiments
â””â”€â”€ docker-compose.yml      # Multi-container orchestration
```

---

## ğŸ“Š Dataset

### Corpus Nummorum (CN) v1
- **Source**: [corpus-nummorum.eu](https://www.corpus-nummorum.eu/)
- **Total Images**: 115,160 ancient coin photographs
- **Original Classes**: 9,716 unique coin types
- **Challenge**: Severe long-tail distribution

### Our Filtered Dataset (Deep Learning Ready)
- **Filtered Classes**: 438 coin types (â‰¥10 images each)
- **Total Images**: 7,677 preprocessed images
- **Average per Class**: 17.5 images
- **Format**: 299Ã—299 RGB JPG (EfficientNet-B3 input size)
- **Preprocessing**: CLAHE enhancement + aspect-preserving resize
- **Train/Val/Test Split**: 70/15/15 stratified split

**Rationale**: CNNs require minimum 10 samples per class for reliable feature learning. Transfer learning from ImageNet reduces this requirement from thousands to tens of images.

---

## ğŸ§  Technical Deep Dive

### Stage 1: Deep Learning Pipeline

#### Image Preprocessing Engine

#### 1. CLAHE Enhancement
```python
# Convert to LAB color space (separates brightness from color)
lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
l, a, b = cv2.split(lab)

# Apply contrast enhancement to lightness channel only
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
l = clahe.apply(l)

# Merge back and convert to BGR
img = cv2.merge((l, a, b))
img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)
```

**Why LAB?** Enhances contrast without distorting coin colors.

#### 2. Aspect-Preserving Resize
- Maintain original aspect ratio
- Add black padding to reach 299Ã—299
- No geometric distortion of coin features

#### CNN Architecture & Training

**EfficientNet-B3** Deep Learning Model:
- **Parameters**: 12M (optimized for mobile/edge deployment)
- **Input**: 299Ã—299Ã—3 RGB tensor
- **Backbone**: Pre-trained on ImageNet (1.2M images, 1000 classes)
- **Feature Extractor**: 1536-dimensional embeddings
- **Classifier Head**: Dropout (p=0.3) + Linear(1536 â†’ 438)
- **Output**: 438-way softmax probabilities

**Training Pipeline**:
1. **Loss Function**: CrossEntropyLoss (multi-class classification)
2. **Optimizer**: AdamW (lr=1e-4, weight_decay=0.01)
3. **Scheduler**: CosineAnnealingLR (warm restarts)
4. **Data Augmentation**: 
   - Rotation (Â±15Â°)
   - Brightness/Contrast (Â±20%)
   - Elastic transforms (simulates coin deformation)
5. **Regularization**: Dropout + weight decay + early stopping
6. **Batch Size**: 32 (gradient accumulation for larger effective batch)
7. **Epochs**: 50 with early stopping (patience=10)

**Transfer Learning Justification**:
- ImageNet pre-training provides low-level features (edges, textures)
- Fine-tuning adapts high-level features to numismatic patterns
- Reduces training data requirement by 10-100x

### Stage 2: Generative AI Multi-Agent System (Coming Soon)

**Vision Agent** â†’ Runs CNN inference  
**Research Agent** â†’ Queries historical database (RAG)  
**Validator Agent** â†’ Cross-references predictions  
**Synthesis Agent** â†’ Generates PDF reports  

**Orchestrator**: LangGraph state machine with conditional routing

---

## ğŸ“ˆ Current Status

### âœ… Completed (Phase 1)
- [x] Project structure & environment setup
- [x] Data auditing & long-tail analysis
- [x] Image preprocessing pipeline (CLAHE + padding)
- [x] EfficientNet-B3 model definition
- [x] Dataset filtering (438 classes, 7,677 images)

### ğŸ”„ In Progress (Phase 2)
- [ ] PyTorch DataLoader with augmentation
- [ ] Training pipeline (loss, optimizer, scheduler)
- [ ] Model evaluation metrics
- [ ] Checkpointing & model versioning

### â³ Planned (Phases 3-7)
- [ ] FastAPI backend (/classify endpoint)
- [ ] Next.js 15 frontend
- [ ] LangGraph multi-agent orchestration
- [ ] ChromaDB RAG system
- [ ] LocalStack cloud simulation
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] Docker deployment

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Frontend** | Next.js 15, TypeScript, Tailwind CSS | Modern web UI |
| **Backend** | FastAPI, Python 3.11, Uvicorn | High-performance API |
| **ML/AI** | PyTorch 2.5, EfficientNet-B3, OpenCV | Computer vision |
| **Agents** | LangGraph, LangChain, OpenAI API | Multi-agent orchestration |
| **Vector DB** | ChromaDB | RAG knowledge base |
| **Database** | PostgreSQL, Redis | Persistence & caching |
| **Cloud Sim** | LocalStack | AWS S3/Lambda emulation |
| **DevOps** | Docker, GitHub Actions, Nginx | CI/CD & deployment |

---

## ğŸ“š Key Concepts

### Long-Tail Distribution
A dataset where few classes have many samples, but most have very few. Our solution: filter classes with <10 images.

### Transfer Learning
Leverage ImageNet pre-training (1.2M images) â†’ fine-tune for coins. **10-100x less data required**.

### CLAHE (Contrast Limited Adaptive Histogram Equalization)
Local contrast enhancement that reveals worn coin details without amplifying noise.

### Agentic Workflow
Multiple specialized AI agents collaborate (Vision + Research + Validator) instead of a single monolithic model.

### RAG (Retrieval-Augmented Generation)
Combine LLM generation with real-time document retrieval to prevent hallucinations.

---

## ğŸ“ Academic Context

**Institution**: [Your University], Tunisia  
**Project Type**: Final Year Engineering Internship (PFE)  
**Domain**: Computer Vision, Deep Learning, Agentic AI  
**Duration**: 16 weeks (February - June 2026)  

**Supervisor Requirements Met**:
- âœ… Archaeological coin recognition system
- âœ… CNN implementation (EfficientNet)
- âœ… Image preprocessing pipeline
- âœ… Database construction & filtering

**Value-Added Beyond Requirements**:
- ğŸš€ Multi-agent orchestration (LangGraph)
- ğŸš€ RAG historical synthesis
- ğŸš€ Cloud-native architecture (LocalStack)
- ğŸš€ Production-ready deployment

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

**Areas for Contribution**:
- Data augmentation strategies
- Model architecture experiments
- Agent prompt engineering
- Frontend UI/UX improvements

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Corpus Nummorum (CN)** for providing the archaeological dataset
- **PyTorch** and **torchvision** teams for excellent ML frameworks
- **LangChain** team for LangGraph agent orchestration tools
- **FastAPI** creators for the modern Python web framework

---

## ğŸ“ Contact

**Author**: Dhia Chaieb  
**Email**: dhiashayeb6@gmail.com  
**LinkedIn**: [linkedin.com/in/dhiachaieb](https://linkedin.com/in/dhiachaieb)  
**GitHub**: [@ChaiebDhia](https://github.com/ChaiebDhia)  

**Project Link**: [https://github.com/ChaiebDhia/DeepCoin-Core](https://github.com/ChaiebDhia/DeepCoin-Core)

---

## ğŸ† Project Goals

### Technical Excellence
- **Accuracy**: Target >85% on test set
- **Speed**: <500ms inference time per image
- **Scalability**: Handle 1000+ concurrent requests (simulated)

### Career Impact
- **Portfolio Differentiator**: Stand out in fullstack/AI job applications
- **Technical Depth**: Demonstrate end-to-end system design skills
- **Modern Stack**: Showcase 2026 industry-standard technologies

### Academic Achievement
- **PFE Grade**: Excellent (18+/20)
- **Innovation**: Multi-agent approach exceeds typical student projects
- **Documentation**: Comprehensive technical writing

---

<div align="center">

**â­ Star this project if you find it interesting!**

Built with â¤ï¸ for archaeological preservation and AI innovation

</div>
